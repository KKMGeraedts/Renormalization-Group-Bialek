{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_visible, n_hidden, CD_depth=5):\n",
    "        super(RBM, self).__init__()\n",
    "        # User input\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "        self.CD_depth = CD_depth\n",
    "\n",
    "        # Model Parameters\n",
    "        initial_weight_variance = 1e-2\n",
    "        self.W = nn.Parameter(torch.randn(n_visible, n_hidden)) * initial_weight_variance\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_visible))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hidden))\n",
    "\n",
    "    def sample_from_p(self, p):\n",
    "        \"\"\"\n",
    "        Sample a binary value from the probability distribution p. p is a 1d array with each value i corresponding\n",
    "        to the probability that variable i is equal to 1. Naturally 1-p is the probablity of 0 then.\n",
    "\n",
    "        Parameters:\n",
    "            p - probability distribution\n",
    "\n",
    "        Return:\n",
    "            sample - the binary sample drawn from p\n",
    "        \"\"\"\n",
    "        uniform_random = torch.rand(p.size())\n",
    "        sample = F.relu(torch.sign(p  - uniform_random))\n",
    "        return sample\n",
    "\n",
    "    def v_to_h(self, v):\n",
    "        h = F.linear(v, self.W.T, self.h_bias)\n",
    "        p_h = F.sigmoid(h)\n",
    "        h = self.sample_from_p(p_h)\n",
    "        return h\n",
    "\n",
    "    def h_to_v(self, h):\n",
    "        v = F.linear(h, self.W, self.v_bias)\n",
    "        p_v = F.sigmoid(v)\n",
    "        v = self.sample_from_p(p_v)\n",
    "        return v\n",
    "\n",
    "    def forward(self, v):\n",
    "        for _ in range(self.CD_depth):\n",
    "            h = self.v_to_h(v)\n",
    "            v = self.h_to_v(h)\n",
    "        return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "epochs = 10\n",
    "n_visible = 40\n",
    "n_hidden = 20\n",
    "lr = 0.01\n",
    "CD_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = RBM(n_visible, n_hidden, CD_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "params = list(rbm.parameters())\n",
    "\n",
    "for i in params:\n",
    "    print(i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karelgeraedts/Documents/uni/Master_Theses/code/Renormalization-Group-Bialek/.venv/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (100x40 and 20x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [74], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m h_reconstructed \u001b[39m=\u001b[39m rbm\u001b[39m.\u001b[39mv_to_h(v_reconstructed)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Compute loss\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m loss \u001b[39m=\u001b[39m lr \u001b[39m*\u001b[39m (v\u001b[39m.\u001b[39;49mmm(h\u001b[39m.\u001b[39;49mT)\u001b[39m.\u001b[39mmean() \u001b[39m-\u001b[39m v_reconstructed\u001b[39m.\u001b[39mmm(v_reconstructed\u001b[39m.\u001b[39mT)\u001b[39m.\u001b[39mmean())\n\u001b[1;32m     25\u001b[0m loss_\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     27\u001b[0m \u001b[39m# Update weights\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (100x40 and 20x100)"
     ]
    }
   ],
   "source": [
    "# Init\n",
    "dataset_size = 1000\n",
    "batch_size = 100\n",
    "n_batches = math.floor(dataset_size / batch_size)\n",
    "\n",
    "# Read data\n",
    "v_data = torch.randn(40, dataset_size).T\n",
    "\n",
    "# Things to keep track of\n",
    "loss_ = []\n",
    "\n",
    "for _ in range(epochs):\n",
    "    # Train network on batches of the data\n",
    "    for i in range(n_batches):\n",
    "        # Batch of input data\n",
    "        v = v_data[i * batch_size: (i+1) * batch_size]\n",
    "\n",
    "        # Pass data through network\n",
    "        h = rbm.v_to_h(v)\n",
    "        v_reconstructed = rbm(v)\n",
    "        h_reconstructed = rbm.v_to_h(v_reconstructed)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = lr * (v.mm(h.T).mean() - v_reconstructed.mm(v_reconstructed.T).mean())\n",
    "        loss_.append(loss)\n",
    "        \n",
    "        # Update weights\n",
    "        loss.backward()\n",
    "        print(v.mm(h.T).mean().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36., 81.]) tensor([-12.,  -8.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "\n",
    "Q = 3*a**3 - b**2\n",
    "\n",
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)\n",
    "\n",
    "print(a.grad, b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "def perform_nmcrg_analysis(activity_data, n_iterations):\n",
    "    # Initialize an RBM model\n",
    "    rbm = BernoulliRBM(n_components=activity_data.shape[1])\n",
    "\n",
    "    # Fit the RBM model to the neural activity data\n",
    "    rbm.fit(activity_data)\n",
    "\n",
    "    # Perform the NMCRG procedure\n",
    "    for _ in range(n_iterations):\n",
    "        # Sample from the current RBM model\n",
    "        samples = rbm.sample(activity_data.shape[0])\n",
    "\n",
    "        # Fit a new RBM model to the samples\n",
    "        rbm.fit(samples)\n",
    "\n",
    "    return rbm\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "37b22bc5a805dff6c1721636ac9d80c3f92f630909bfe11b0de479b14a3a34e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
