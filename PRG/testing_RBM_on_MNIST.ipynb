{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from RBM import RBM\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "from data_cleaning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karelgeraedts/Documents/uni/Master_Theses/code/Renormalization-Group-Bialek/.venv/lib/python3.10/site-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/karelgeraedts/Documents/uni/Master_Theses/code/Renormalization-Group-Bialek/.venv/lib/python3.10/site-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_dataset = mnist_trainset.test_data.shape[0]\n",
    "v_data = mnist_trainset.train_data.reshape(size_dataset, -1).float()\n",
    "v_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(v_data):\n",
    "    stds = torch.std(v_data, dim=0)\n",
    "    print(torch.argwhere(stds == 0).numpy())\n",
    "    return (v_data - torch.mean(v_data, dim=0)) / torch.std(v_data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 20]), 'torch.FloatTensor')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Ebo's dataset\n",
    "f = \"data/HG19_k6_datasets/HG19_k6_mu0.00_(20,4,5)_B0.55_N1000_00.dat\"\n",
    "v_data = read_input(f)\n",
    "v_data = torch.tensor(v_data).float()\n",
    "v_data.size(), v_data.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 10.2100\n",
      "Epoch [20/100], Loss: 7.7600\n",
      "Epoch [30/100], Loss: 9.5200\n",
      "Epoch [40/100], Loss: 9.3700\n",
      "Epoch [50/100], Loss: 9.6300\n",
      "Epoch [60/100], Loss: 10.5400\n",
      "Epoch [70/100], Loss: 10.5100\n",
      "Epoch [80/100], Loss: 11.7200\n",
      "Epoch [90/100], Loss: 8.8100\n",
      "Epoch [100/100], Loss: 10.9600\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "epochs = 100\n",
    "n_visible = v_data.shape[1]\n",
    "n_hidden = 5\n",
    "lr = 0.01\n",
    "CD_depth = 5\n",
    "batch_size = 50\n",
    "\n",
    "# Normalize data s.t. N(0, 1)\n",
    "#v_data = normalize_data(v_data)\n",
    "\n",
    "# Create RBM layer\n",
    "rbm = RBM(n_visible, n_hidden, CD_depth)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(rbm.parameters(), lr=lr)\n",
    "\n",
    "# Things to keep track of\n",
    "loss_ = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Randomly permute the dataset\n",
    "    v_data = v_data[torch.randperm(v_data.size()[0])]\n",
    "\n",
    "    for i in range(0, len(v_data), batch_size):\n",
    "        # Get batch\n",
    "        v_batch = v_data[i:i+batch_size]\n",
    "\n",
    "        # Forward\n",
    "        h_batch, _ = rbm.v_to_h(v_batch)\n",
    "        v_forward = rbm(v_batch)\n",
    "        h_forward, _ = rbm.v_to_h(v_forward)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = -1 * ((v_batch.T @ h_batch).mean() - (v_forward.T @ h_forward).mean())\n",
    "        loss_.append(loss)\n",
    "        \n",
    "        # # Backward\n",
    "        # loss.backward(retain_graph=True)\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 100, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in rbm.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37b22bc5a805dff6c1721636ac9d80c3f92f630909bfe11b0de479b14a3a34e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
